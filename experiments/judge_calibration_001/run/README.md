# Experiment Run: LLM Judge Calibration

This directory contains the execution code and data for the LLM Judge Calibration experiment.

## Files Structure
- `judge_evaluation.py` - Main experiment execution script
- `prompts/` - Judge prompting strategies
- `data/` - Sample AI outputs and human ratings
- `results/` - Correlation analysis and calibration metrics