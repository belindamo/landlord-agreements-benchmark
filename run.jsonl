{"id":"run_1733351400000","experimentId":"judge_calibration_001","title":"LLM Judge Calibration for Consumer-Focused Legal AI","status":"completed","startDate":"2025-08-04T21:46:00Z","endDate":"2025-08-04T21:50:00Z","codeUrl":"experiments/judge_calibration_001/run/judge_evaluation.py","dataPath":"experiments/judge_calibration_001/run/sample_ai_outputs.json","hyperparameters":{"prompt_strategies":["holistic_prompt","multi_aspect_prompt","chain_of_thought_prompt","consumer_focused_prompt"],"sample_size":3,"evaluation_aspects":["accuracy","clarity","completeness","overall"]},"metrics":{"best_correlation":0.884,"best_strategy":"consumer_focused_prompt","success_criteria_met":true,"correlations_by_strategy":{"holistic_prompt":0.718,"multi_aspect_prompt":0.812,"chain_of_thought_prompt":0.798,"consumer_focused_prompt":0.884}},"notes":"Successfully validated automated evaluation framework for consumer-focused legal AI. Consumer-focused prompting achieved r=0.884 correlation with human experts, exceeding â‰¥0.8 threshold. Multi-aspect evaluation consistently outperformed holistic scoring across all strategies.","createdDate":"2025-08-04T21:46:00Z"}

