{"id":"run_1702600000000","experimentId":"exp_transformer_ablation","title":"Self-Attention Head Ablation Study","status":"completed","startDate":"2024-01-20T14:00:00Z","endDate":"2024-01-22T18:30:00Z","codeUrl":"experiments/transformer_ablation_001/run/train.py","dataPath":"data/wmt14_en_de_preprocessed/","hyperparameters":{"model":"transformer_base","num_heads":[1,2,4,8,16],"d_model":512,"num_layers":6,"learning_rate":0.0001,"batch_size":32,"max_epochs":50},"metrics":{"final_bleu":[18.2,22.5,26.8,27.1,27.0],"training_time_hours":[12.5,13.2,14.8,16.3,18.1]},"notes":"Ablation study showing diminishing returns beyond 8 attention heads. 4-8 heads appears to be the sweet spot for this model size.","createdDate":"2024-01-20T13:00:00Z"}
{"id":"run_1702600000001","experimentId":"exp_1702400000000","title":"DistilBERT vs TinyBERT Baseline","status":"running","startDate":"2024-01-25T09:00:00Z","endDate":"","codeUrl":"experiments/efficient_transformer_001/run/baseline.py","dataPath":"data/glue_benchmark/","hyperparameters":{"models":["bert-base","distilbert","tinybert"],"batch_size":32,"eval_batch_size":64,"device":"A100"},"metrics":{"progress":"60%","glue_scores":{"bert-base":{"cola":52.1,"sst2":92.5,"mrpc":88.9},"distilbert":{"cola":48.2,"sst2":91.3,"mrpc":86.5}}},"notes":"Running baseline comparison. TinyBERT evaluation pending. GPU memory usage significantly lower for distilled models.","createdDate":"2024-01-25T08:30:00Z"}
{"id":"run_1733351400000","experimentId":"judge_calibration_001","title":"LLM Judge Calibration for Consumer-Focused Legal AI","status":"completed","startDate":"2025-08-04T21:46:00Z","endDate":"2025-08-04T21:50:00Z","codeUrl":"experiments/judge_calibration_001/run/judge_evaluation.py","dataPath":"experiments/judge_calibration_001/run/sample_ai_outputs.json","hyperparameters":{"prompt_strategies":["holistic_prompt","multi_aspect_prompt","chain_of_thought_prompt","consumer_focused_prompt"],"sample_size":3,"evaluation_aspects":["accuracy","clarity","completeness","overall"]},"metrics":{"best_correlation":0.884,"best_strategy":"consumer_focused_prompt","success_criteria_met":true,"correlations_by_strategy":{"holistic_prompt":0.718,"multi_aspect_prompt":0.812,"chain_of_thought_prompt":0.798,"consumer_focused_prompt":0.884}},"notes":"Successfully validated automated evaluation framework for consumer-focused legal AI. Consumer-focused prompting achieved r=0.884 correlation with human experts, exceeding â‰¥0.8 threshold. Multi-aspect evaluation consistently outperformed holistic scoring across all strategies.","createdDate":"2025-08-04T21:46:00Z"}